{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0Ty2cQBbH2Lz3KnYgvKUx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryan-at-ul/image_segmentation/blob/main/pneumonia_image_as_graph_classification_resnet_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4TWA3mGD1S4"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install imageio==2.22.4\n",
        "!pip install llvmlite==0.39.1\n",
        "!pip install matplotlib==3.6.2\n",
        "!pip install networkx==2.8.8\n",
        "!pip install numba==0.56.4\n",
        "!pip install numpy\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install psutil==5.9.4\n",
        "!pip install pytz==2022.6\n",
        "!pip install scikit-image==0.19.3\n",
        "!pip install scipy \n",
        "!pip install timm==0.6.12\n",
        "!pip install torch==1.13.0\n",
        "!pip install torchinfo==1.7.1\n",
        "!pip install torchvision==0.14.0\n",
        "# tqdm @ file:///opt/conda/conda-bld/tqdm_1647339053476/work\n",
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric \n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "from torch_geometric.loader import DataLoader\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.nn import Sequential as Seq, Linear, ReLU\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops\n",
        "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv, JumpingKnowledge\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "from torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "# from torch_geometric.logging import init_wandb, log\n",
        "from torch_geometric.nn import GCNConv\n",
        "import random\n",
        "from torch.nn import Linear, ReLU, Dropout\n",
        "from torch_geometric.nn import Sequential, GCNConv, JumpingKnowledge\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool"
      ],
      "metadata": {
        "id": "pcJvDhVKF-VY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o train_dataloader.pkl -L 'https://drive.google.com/uc?export=download&confirm=yes&id=1luFl1j_zf07eD_CHrpprXPz1udCIhjUU'\n",
        "!curl -o test_dataloader.pkl -L 'https://drive.google.com/uc?export=download&confirm=yes&id=115kJ5EzpCL7TXLKUotJXuK6ngwcyC84E'\n",
        "!curl -o val_dataloader.pkl -L 'https://drive.google.com/uc?export=download&confirm=yes&id=1SlQqiqT6vAlotmT9xc5PMQdeFLTh_PUa'"
      ],
      "metadata": {
        "id": "lPbfNtU3J2M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh * "
      ],
      "metadata": {
        "id": "u4Q7zuaqJQvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "curretn_path = os.getcwd()\n",
        "path = f\"{curretn_path}\"\n",
        "\n",
        "embed_dim = 128\n",
        "\n",
        "def load_all_from_one_folder(path,type = 0):\n",
        "    all_files = os.listdir(path)\n",
        "    all_data = []\n",
        "    k = 0\n",
        "    for one_g in all_files:\n",
        "        name = one_g.split(\".\")[0]\n",
        "        G = nx.read_gpickle(f\"{path}/{one_g}\")  \n",
        "\n",
        "        data = from_networkx(G)\n",
        "        if type:\n",
        "            data.y = [1]\n",
        "        else:\n",
        "            data.y = [0]\n",
        "        k+= 1\n",
        "        data.x = torch.Tensor([torch.flatten(val).tolist() for val in data.x])#nx.get_node_attributes(G,'image')\n",
        "        data.name = name\n",
        "        all_data.append(data)\n",
        "    return all_data\n",
        "\n",
        "\n",
        "def permute_array(array):\n",
        "    permuted_array = []\n",
        "    for i in range(len(array)):\n",
        "        permuted_array.append(array[i])\n",
        "    return permuted_array\n",
        "\n",
        "def check_if_a_with_name_exisi(path,name):\n",
        "    all_files = os.listdir(path)\n",
        "    if name in all_files:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dataloader():\n",
        "    \"\"\"\n",
        "    load train and test data\n",
        "    \"\"\"\n",
        "    print(\"loading data\")\n",
        "    train_dataset, test_dataset, val_dataset = None, None, None\n",
        "\n",
        "    if not check_if_a_with_name_exisi(curretn_path,'train_dataloader.pkl'):\n",
        "\n",
        "        train_normal = load_all_from_one_folder(f\"{path}/train/NORMAL\")\n",
        "        train_pneumonia = load_all_from_one_folder(f\"{path}/train/PNEUMONIA\",1)\n",
        "\n",
        "        test_normal = load_all_from_one_folder(f\"{path}/test/NORMAL\")\n",
        "        test_pneumonia = load_all_from_one_folder(f\"{path}/test/PNEUMONIA\",1)\n",
        "\n",
        "        val_normal = load_all_from_one_folder(f\"{path}/val/NORMAL\")\n",
        "        val_pneumonia = load_all_from_one_folder(f\"{path}/val/PNEUMONIA\",1)\n",
        "\n",
        "\n",
        "        train_data_arr = train_normal + train_pneumonia\n",
        "        test_data_arr = test_normal + test_pneumonia\n",
        "        val_data_arr = val_normal + val_pneumonia\n",
        "        # all_data = permute_array(all_data)\n",
        "        random.shuffle(train_data_arr)\n",
        "        random.shuffle(test_data_arr)\n",
        "        random.shuffle(val_data_arr)\n",
        "        \n",
        "        train_dataset = train_data_arr#all_data[:int(len(all_data)*0.8)]\n",
        "        val_dataset = val_data_arr#all_data[int(len(all_data)*0.8):int(len(all_data)*0.8) + 100]\n",
        "        test_dataset = test_data_arr#all_data[int(len(all_data)*0.8):]\n",
        "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,drop_last=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False,drop_last=True)\n",
        "        # test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True,drop_last=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True,drop_last=True)\n",
        "\n",
        "        with open('train_dataloader.pkl', 'wb') as f:\n",
        "            pickle.dump(train_loader, f)\n",
        "\n",
        "        with open('test_dataloader.pkl', 'wb') as f:\n",
        "            pickle.dump(test_loader, f)\n",
        "        \n",
        "        with open('val_dataloader.pkl', 'wb') as f:\n",
        "            pickle.dump(val_loader, f)\n",
        "    else:\n",
        "        with open('train_dataloader.pkl', 'rb') as f:\n",
        "            train_loader = pickle.load(f)\n",
        "\n",
        "        with open('test_dataloader.pkl', 'rb') as f:\n",
        "            test_loader = pickle.load(f)\n",
        "        \n",
        "        with open('val_dataloader.pkl', 'rb') as f:\n",
        "            val_loader = pickle.load(f)\n",
        "\n",
        "\n",
        "    return train_loader, test_loader, train_dataset, test_dataset, val_loader, val_dataset\n",
        "\n",
        "\n",
        "\n",
        "train_loader, test_loader, train_dataset, test_dataset, val_loader, val_dataset = dataloader()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"data loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emKmWPHjK4Ag",
        "outputId": "ad5a096b-6b95-44a2-8196-a60fd92499d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "data loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.conv1 = GCNConv(512, 256)\n",
        "        self.conv2 = GCNConv(256, 128)\n",
        "        self.conv3 = GCNConv(128,64)\n",
        "        self.conv4 = GCNConv(64, 32)\n",
        "        self.lin1 = Linear(32, 16)\n",
        "        self.lin = Linear(16, 2)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv4(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, batch)  \n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.6, training=self.training)\n",
        "        x = self.lin1(x)\n",
        "        x = x.relu()\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=512) # based on feature size"
      ],
      "metadata": {
        "id": "qTm7eTPJLWgO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "FuXxeGraLoUe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    for data in train_loader: \n",
        "        out = model(data.x, data.edge_index, data.batch) \n",
        "        data.y = torch.Tensor(data.y)\n",
        "        data.y = torch.Tensor(torch.flatten(data.y))\n",
        "        data.y = data.y.type(torch.LongTensor)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()  \n",
        "\n",
        "def test(loader):\n",
        "     model.eval()\n",
        "\n",
        "     correct = 0\n",
        "     for data in loader:  \n",
        "         out = model(data.x, data.edge_index, data.batch)  \n",
        "         data.y = torch.Tensor(data.y)\n",
        "         pred = out.argmax(dim=1).view(-1,1)  \n",
        "         correct += int((pred == data.y).sum())  \n",
        "         acc = correct / len(loader.dataset)\n",
        "        #  if acc > 0.91:\n",
        "        #      torch.save(model.state_dict(), 'model_res_10sp.pt')\n",
        "     return correct / len(loader.dataset) \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ppE-wHALpU8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 21):\n",
        "    train()\n",
        "    try:\n",
        "        train_acc = test(train_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "    except Exception as e:\n",
        "        print(\"error\",e)\n",
        "        pass\n",
        "\n",
        "print(\"number of paramteres for this model\",sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkJRDvCXL6G1",
        "outputId": "47dddb39-4227-4f1e-b933-d9df82c3a19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Train Acc: 0.9699, Test Acc: 0.7933\n",
            "Epoch: 002, Train Acc: 0.9787, Test Acc: 0.8478\n",
            "Epoch: 003, Train Acc: 0.9799, Test Acc: 0.8510\n",
            "Epoch: 004, Train Acc: 0.9804, Test Acc: 0.8381\n",
            "Epoch: 005, Train Acc: 0.9795, Test Acc: 0.8413\n",
            "Epoch: 006, Train Acc: 0.9795, Test Acc: 0.8157\n",
            "Epoch: 007, Train Acc: 0.9814, Test Acc: 0.8237\n",
            "Epoch: 008, Train Acc: 0.9814, Test Acc: 0.8478\n",
            "Epoch: 009, Train Acc: 0.9793, Test Acc: 0.8478\n",
            "Epoch: 010, Train Acc: 0.9711, Test Acc: 0.7724\n"
          ]
        }
      ]
    }
  ]
}